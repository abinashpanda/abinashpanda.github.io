<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Parsing | Pythonic Musings]]></title>
  <link href="http://abinashpanda.github.io/blog/categories/parsing/atom.xml" rel="self"/>
  <link href="http://abinashpanda.github.io/"/>
  <updated>2013-10-19T23:33:33+05:30</updated>
  <id>http://abinashpanda.github.io/</id>
  <author>
    <name><![CDATA[Abinash Panda]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Parsing Data From IMDb 'II']]></title>
    <link href="http://abinashpanda.github.io/blog/2013/10/19/parsing-data-from-imdb-ii/"/>
    <updated>2013-10-19T20:57:00+05:30</updated>
    <id>http://abinashpanda.github.io/blog/2013/10/19/parsing-data-from-imdb-ii</id>
    <content type="html"><![CDATA[<p>In the <a href="/blog/2013/10/18/parsing-data-from-imdb-I/">previous post</a>, I wrote a simple parser to parse <a href="http://www.imdb.com/chart/top">IMDb Top 250</a>. That was a simple parser that was able to get movie&rsquo;s rating and year. This post is about writing a bit more complex and more powerful crawler. For this crawler, I have taken some concepts from <code>scrapy</code> <em>(imitation is the best form of flattery)</em> and have used <code>lxml</code> for scraping.</p>

<p>I would be scraping the <a href="http://www.imdb.com/year">IMDb: Years</a> page. This page contains the links for pages containing the links for <em>Most Popular Titles Released</em> in that year. In the next blog, I would be using the data scraped (a dictionary <code>{year: [name, rating, genres, director, actors]}</code> for analysing trends in Movies.</p>

<p>```python Crawler.py
import urllib2
import re
from lxml.html import parse</p>

<p>class Crawler():</p>

<pre><code>def __init__(self, settings):
    """
    settings should be a dictionary containing
    domain:
    start_url:

    EXAMPLE
    settings = {'domain': 'http://www.imdb.com', 'start_url': '/year'}
    """
    self.settings = settings
    self.rules = {self.settings['start_url']: 'parse'}
    self.parsed_urls = []
    self.url_list = []

def _get_all_urls(self, response):
    """
    _get_all_urls returns all the urls in the page
    """
    tree = parse(response)
    url_list = tree.findall('//a')
    url_list = [url.attrib['href']
                if url.attrib['href'].startswith('http://')
                else urllib2.urlparse.urljoin(self.settings['domain'],
                                              url.attrib['href'])
                for url in url_list]
    return url_list

def set_rules(self, rules):
    """
    set_rules set the rules for crawling
    rules are dictionary in the form
    {url_pattern: parsing_function}

    EXAMPLE
    &gt;&gt;&gt; settings = {'domain': 'http://www.imdb.com', 'start_url': '/year'}
    &gt;&gt;&gt; imdb_crawler = Crawler(settings)
    &gt;&gt;&gt; imdb_crawler.set_rules({'/year/\d+': 'year_parser',
    ...                         '/title/\w+': 'movie_parser'})
    """
    self.rules = rules

def _get_crawl_function(self, url):
    """
    _get_crawl_function returns the crawl function to be
    used for given url pattern
    """
    for pattern in self.rules.keys():
        if re.search(pattern, url):
            return self.rules[pattern]

def parse(self, response):
    """
    parse is the default parser to be called
    """
    pass

def start_crawl(self):
    """
    start_crawl is the method that starts calling

    EXAMPLE
    &gt;&gt;&gt; foo_crawler = Crawler()
    &gt;&gt;&gt; foo_crawler.start_crawl()
    """
    response = urllib2.urlopen(
        urllib2.urlparse.urljoin(self.settings['domain'],
                                 self.settings['start_url']))
    self.url_list = self._get_all_urls(response)
    for url in self.url_list:
        if url not in self.parsed_urls:
            crawl_function = self._get_crawl_function(url)
            if crawl_function:
                getattr(self, crawl_function)(urllib2.urlopen(url))
                self.parsed_urls.append(url)
</code></pre>

<p><code>
*Crawler* object have to be initailized with a dictionary *settings* &lt;code&gt;{'domain': domain\_of_\page, 'start\_url': start\_url\_page}&lt;/code&gt;
The *Crawler* class has attribute *url_list* that contains all the urls to be parsed and *parsed\_urls* is a list of all the parsed urls.
</code>python <em>get_all_urls
def </em>get_all_urls(self, response):</p>

<pre><code>"""
_get_all_urls returns all the urls in the page
"""
tree = parse(response)
url_list = tree.findall('//a')
url_list = [url.attrib['href']
            if url.attrib['href'].startswith('http://')
            else urllib2.urlparse.urljoin(self.settings['domain'],
                                          url.attrib['href'])
            for url in url_list]
return url_list  
</code></pre>

<p>```
<code>_get_all_urls</code> retrieves all the <em>urls</em> present in the web page. <code>tree.findall(&lsquo;//a&rsquo;)</code> would return all the <em>//a</em> tags present in the web page. If the url starts with <a href="http://">http://</a> then it would append it as usual; but if the url is a relative url, it would append the final url formed by joining the url with the domain <div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">urllib2</span><span class="o">.</span><span class="n">urlparse</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">settings</span><span class="p">[</span><span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="n">domain</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;],</span> <span class="n">url</span><span class="o">.</span><span class="n">attrib</span><span class="p">[</span><span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="n">href</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<code>parse(response)</code> is the default parser of the Crawler. More sophisticated or complex parsers can be written for different urls using <code>set_rule</code>. For example:</p>

<p>```python set_rule
settings = {&lsquo;domain&rsquo;: &lsquo;<a href="http://www.imdb.com">http://www.imdb.com</a>&rsquo;, &lsquo;start_url&rsquo;: &lsquo;/year&rsquo;}
imdb_crawler = Crawler(settings)</p>

<h1>year_parser is parser for scraping year pages</h1>

<h1>movie_parser is parser for scraping movie pages</h1>

<p>imdb_crawler.set_rules({&lsquo;/year/\d+&rsquo;: &lsquo;year_parser&rsquo;,</p>

<pre><code>                    '/title/\w+': 'movie_parser'})
</code></pre>

<p>```
<em>All the parser should have be an input parameter <code>response</code>.</em> Discussed below in details.</p>

<p>```python start_crawl
def start_crawl(self):</p>

<pre><code>"""
start_crawl is the method that starts calling

EXAMPLE
&gt;&gt;&gt; foo_crawler = Crawler()
&gt;&gt;&gt; foo_crawler.start_crawl()
"""
response = urllib2.urlopen(
    urllib2.urlparse.urljoin(self.settings['domain'],
                             self.settings['start_url']))
self.url_list = self._get_all_urls(response)
for url in self.url_list:
    if url not in self.parsed_urls:
        crawl_function = self._get_crawl_function(url)
        if crawl_function:
            getattr(self, crawl_function)(urllib2.urlopen(url))
            self.parsed_urls.append(url)
</code></pre>

<p>```
<code>start_crawl</code> is the main function that initiates crawling. First, it tries to get all the <em>urls</em> present in the start_page. It then searches the parser to be called for that particular url using <code>_get_crawl_function</code>.
<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">_get_crawl_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="s">&quot;&quot;&quot;</span>
</span><span class='line'><span class="s">_get_crawl_function returns the crawl function to be</span>
</span><span class='line'><span class="s">used for given url pattern</span>
</span><span class='line'><span class="s">&quot;&quot;&quot;</span>
</span><span class='line'><span class="k">for</span> <span class="n">pattern</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">url</span><span class="p">):</span>
</span><span class='line'>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules</span><span class="p">[</span><span class="n">pattern</span><span class="p">]</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
The particular parser is then called according to rules set above. Finally the url is appended into <em>parsed_urls</em> list.</p>

<p>Using the above <code>Crawler</code>, I have implemented <code>IMDbCrawler</code>.
```python main.py
from Crawler import Crawler
from collections import defaultdict</p>

<p>movie_final_dict = defaultdict(list)</p>

<p>class IMDbCrawler(Crawler):</p>

<pre><code>def year_parser(self, response):
    tree = parse(response)
    year = tree.find('//*[@id="header"]/h1')
    print year.text
    list_even = tree.findall(
        '//table//tr[@class="even detailed"]/td[@class="title"]/a')
    list_odd = tree.findall(
        '//table//tr[@class="odd detailed"]/td[@class="title"]/a')
    movies_list = list_even + list_odd
    movies_list_url = [urllib2.urlparse.urljoin(self.settings['domain'],
                                                movie.attrib['href'])
                       for movie in movies_list]
    for url in movies_list_url:
        self.url_list.append(url)

def movie_parser(self, response):
    tree = parse(response)
    name = tree.find('//*[@id="overview-top"]/h1/span[1]').text
    print name
    try:
        genres = tree.findall('//div[@itemprop="genre"]//a')
        genres = [genre.text.strip() for genre in genres]
        director = tree.find(
            '//div[@itemprop="director"]//span[@itemprop="name"]')
        director = director.text.strip()
        rating = tree.find('//span[@itemprop="ratingValue"]')
        rating = float(rating.text)
        actors = tree.findall('//td[@itemprop="actor"]//a//span')
        actors = [actor.text.strip() for actor in actors]
        year = tree.find('//*[@id="overview-top"]/h1/span[2]/a').text
        movie_final_dict[year].append([name, rating,
                                       genres, director, actors])
    except (AttributeError, IndexError):
        pass
</code></pre>

<p>settings = {&lsquo;domain&rsquo;: &lsquo;<a href="http://www.imdb.com">http://www.imdb.com</a>&rsquo;, &lsquo;start_url&rsquo;: &lsquo;/year&rsquo;}
imdb_crawler = IMDbCrawler(settings)
imdb_crawler.set_rules({&lsquo;/year/\d+&rsquo;: &lsquo;year_parser&rsquo;,</p>

<pre><code>                    '/title/\w+': 'movie_parser'})
</code></pre>

<p>imdb_crawler.start_crawl()
```</p>

<p><code>IMDbCrawler</code> has inherited <em>Crawler</em> class.</p>

<p>```python year_parser
def year_parser(self, response):</p>

<pre><code>tree = parse(response)
year = tree.find('//*[@id="header"]/h1')
print year.text
list_even = tree.findall(
    '//table//tr[@class="even detailed"]/td[@class="title"]/a')
list_odd = tree.findall(
    '//table//tr[@class="odd detailed"]/td[@class="title"]/a')
movies_list = list_even + list_odd
movies_list_url = [urllib2.urlparse.urljoin(self.settings['domain'],
                                            movie.attrib['href'])
                   for movie in movies_list]
for url in movies_list_url:
    self.url_list.append(url)
</code></pre>

<p><code>
&lt;code&gt;year_parser&lt;/code&gt; would crawl *year pages* and append the *movie pages* into &lt;code&gt;url\_list&lt;/code&gt;. *XPath* for extracting *movie url* and *year name* is discussed [here](/blog/2013/10/18/parsing-data-from-imdb-I/).
</code>python movie_parser
def movie_parser(self, response):</p>

<pre><code>tree = parse(response)
name = tree.find('//*[@id="overview-top"]/h1/span[1]').text
print name
try:
    genres = tree.findall('//div[@itemprop="genre"]//a')
    genres = [genre.text.strip() for genre in genres]
    director = tree.find(
        '//div[@itemprop="director"]//span[@itemprop="name"]')
    director = director.text.strip()
    rating = tree.find('//span[@itemprop="ratingValue"]')
    rating = float(rating.text)
    actors = tree.findall('//td[@itemprop="actor"]//a//span')
    actors = [actor.text.strip() for actor in actors]
    year = tree.find('//*[@id="overview-top"]/h1/span[2]/a').text
    movie_final_dict[year].append([name, rating,
                                   genres, director, actors])
except (AttributeError, IndexError):
    pass
</code></pre>

<p>```
<code>movie_parser</code> would crawl the movie web page and add the details of the movies such as its <em>ratings, director, genres</em> in the dictionary <em>movie_final_dict</em>. There are some movies where data (rating, actors, etc.) is missing, so I have included <em>try</em> and <em>except</em> statements.
<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">settings</span> <span class="o">=</span> <span class="p">{</span><span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="n">domain</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;:</span> <span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s">&quot;http://www.imdb.com&quot;</span><span class="o">&gt;</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">com</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;&amp;</span><span class="n">rsquo</span><span class="p">;,</span> <span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="n">start_url</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;:</span> <span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="o">/</span><span class="n">year</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;}</span>
</span><span class='line'><span class="n">imdb_crawler</span> <span class="o">=</span> <span class="n">IMDbCrawler</span><span class="p">(</span><span class="n">settings</span><span class="p">)</span>
</span><span class='line'><span class="n">imdb_crawler</span><span class="o">.</span><span class="n">set_rules</span><span class="p">({</span><span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="o">/</span><span class="n">year</span><span class="o">/</span>\<span class="n">d</span><span class="o">+&amp;</span><span class="n">rsquo</span><span class="p">;:</span> <span class="o">&amp;</span><span class="n">lsquo</span><span class="p">;</span><span class="n">year_parser</span><span class="o">&amp;</span><span class="n">rsquo</span><span class="p">;,</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span>                    <span class="s">&#39;/title/\w+&#39;</span><span class="p">:</span> <span class="s">&#39;movie_parser&#39;</span><span class="p">})</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">imdb_crawler</span><span class="o">.</span><span class="n">start_crawl</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<code>imdb_crawler</code> is an instance of <em>IMDbCrawler</em>. It has been instantiated with the <em>domain</em> <a href="http://www.imdb.com">http://www.imdb.com</a> and <em>start_url</em> /year. Then the rules are set for different urls. It would call <em>year_parser</em> for all the webpages in the format of <a href="http://www.imdb.com/year/1992">http://www.imdb.com/year/1992</a> and
<em>movie_parser</em> for webpages in the format of <a href="http://www.imdb.com/title/tt0477348/.">http://www.imdb.com/title/tt0477348/.</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parsing Data from IMDb 'I']]></title>
    <link href="http://abinashpanda.github.io/blog/2013/10/18/parsing-data-from-imdb-I/"/>
    <updated>2013-10-18T23:44:00+05:30</updated>
    <id>http://abinashpanda.github.io/blog/2013/10/18/parsing-data-from-imdb-I</id>
    <content type="html"><![CDATA[<p><a href="http://www.imdb.com">IMDb</a> is an online database of information related to films, television programs and video games. I woulb be going to parse <a href="http://www.imdb.com/chart/top">IMDb Top 250</a> and <a href="http://www.imdb.com/year">IMDb: Years</a> and extract information about the movies ratings, year of release, start casts, directors, etc.</p>

<p>```python main.py</p>

<h1>!/usr/bin/env python</h1>

<p>from lxml.html import parse</p>

<p>tree = parse(&lsquo;<a href="http://www.imdb.com/chart/top">http://www.imdb.com/chart/top</a>&rsquo;)</p>

<p>movies_data = tree.findall(&lsquo;//<em>[@id=&ldquo;main&rdquo;]/table[2]/tr/td[3]/font/a&rsquo;)
movies_rating = tree.findall(&lsquo;//</em>[@id=&ldquo;main&rdquo;]/table[2]/tr/td[2]/font&rsquo;)</p>

<h1>Removing unwanted data</h1>

<p>movies_data.pop(0)
movies_rating.pop(0)</p>

<p>movies_rating = [float(movie.text) for movie in movies_rating]</p>

<p>def get_movie_data(iterator):</p>

<pre><code>movie_data = (iterator.next(), iterator.next())
return movie_data
</code></pre>

<p>mov_dict = {get_movie_data(movies_data[i].itertext())[0]:</p>

<pre><code>        [int(get_movie_data(movies_data[i].itertext())[1].strip(' ()/I')),
         movies_rating[i]] for i in range(len(movies_data))}
</code></pre>

<p>```</p>

<p>Going through the code in details. For this simple parser I have used <strong>parse</strong> from <strong>lxml.html</strong>.</p>

<p><code>tree = parse(&lsquo;<a href="http://www.imdb.com/chart/top">http://www.imdb.com/chart/top</a>&rsquo;)</code> parses the <a href="http://www.imdb.com/chart/top">url</a> and returns a tree.<br/>
Before going on the next line, lets discuss about <strong>XPath</strong>. XPath, the XML Path Language, is a query language for selecting nodes from an XML document. <a href="http://www.w3schools.com/xpath/">XPath Tutorial</a> is a very good tutorial for XPath by w3cschools.com. In the XPath,
<code>&lsquo;//*[@id=&ldquo;main&rdquo;]/table[2]/tr/td[3]/font/a&rsquo;</code></p>

<pre><code>// : Selects nodes in the document from the current node
     that match the selection no matter where they are.  
/ : Selects from the root node  
/tr/td[3]: Selects the third td element that is the child of the tr element.   
</code></pre>

<p>To get the XPath of an element, you can use Google Chrome.
Click on <strong>Inspect Element</strong>.
<img src="/images/screen1.jpg"><br/>
Then select <strong>Copy XPath</strong>.
This would give you the XPath to be used. <strong>Remember to remove &lt;tbody&gt; element from the XPath. and also remove [] from tr as you want to scrape the whole movies list.</strong><br/>
Similarly you can find the XPath for movies_rating also.</p>

<p>Then in
```python get_movie_data
def get_movie_data(iterator):</p>

<pre><code>""" Returns movie_name, year_of_release as movies_data[element].itertext()
would return an iterator containing these two elements"""
movie_data = (iterator.next(), iterator.next())
return movie_data
</code></pre>

<p>mov_dict = {get_movie_data(movies_data[i].itertext())[0]:</p>

<pre><code>        [int(get_movie_data(movies_data[i].itertext())[1].strip(' ()/I')),
         movies_rating[i]] for i in range(len(movies_data))}
</code></pre>

<p>```
<strong>mov_dict</strong> is built containing the dictionary with</p>

<pre><code>key: movie_name
value: year_of_release, moving_rating
</code></pre>
]]></content>
  </entry>
  
</feed>
